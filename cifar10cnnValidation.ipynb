{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify CNN\n",
    "The .pth file doesn't contain the architecture itself. Only the weights. Thus we need to re-state the model's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Convolutional layers\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    # Forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n",
    "Loads the pre-trained model in order to test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \"\"\"Load the trained model from .pth file\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CNN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    model.eval()\n",
    "    return model, device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom image\n",
    "- Custom image transformation for classification\n",
    "- Custom image denormalization for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_image(image_path, size=(32, 32)):\n",
    "    \"\"\"Prepare a custom image for inference using the same transformations as training\"\"\"\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure the image is in RGB format\n",
    "    \n",
    "    # Apply transformations to get the tensor\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    # Denormalize for visualization\n",
    "    denormalize = transforms.Normalize(\n",
    "        mean=[-0.4914 / 0.2023, -0.4822 / 0.1994, -0.4465 / 0.2010],\n",
    "        std=[1 / 0.2023, 1 / 0.1994, 1 / 0.2010]\n",
    "    )\n",
    "    denormalized_tensor = denormalize(image_tensor.squeeze(0))\n",
    "    resized_image = denormalized_tensor.permute(1, 2, 0).clamp(0, 1).numpy()  # Convert to NumPy and clamp values to [0, 1]\n",
    "    resized_image = (resized_image * 255).astype(np.uint8)  # Scale to [0, 255]\n",
    "    \n",
    "    # Debug information\n",
    "    print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "    print(f\"Value range: [{image_tensor.min():.2f}, {image_tensor.max():.2f}]\")\n",
    "    \n",
    "    return image_tensor, resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random CIFAR image\n",
    "Get a random image from inside the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cifar_image():\n",
    "    \"\"\"Get a random image from CIFAR-10 test set\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    \n",
    "    testset = torchvision.datasets.CIFAR10(root='./cifar-10-batches-py', train=False,\n",
    "                                          download=True, transform=transform)\n",
    "    idx = random.randint(0, len(testset) - 1)\n",
    "    image, label = testset[idx]\n",
    "    return image.unsqueeze(0), label, testset.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_tensor, device):\n",
    "    \"\"\"Make a prediction on the input image\"\"\"\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        return predicted.item(), probs[0].cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display predicted input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(image, prediction, probabilities=None, title=None):\n",
    "    \"\"\"Display the image and prediction\"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    # If image is a PIL Image, convert to numpy array\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image) / 255.0\n",
    "    # If image is a tensor, convert to numpy and denormalize\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.numpy().transpose((1, 2, 0))\n",
    "        # Denormalize\n",
    "        mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "        std = np.array([0.2023, 0.1994, 0.2010])\n",
    "        image = std * image + mean\n",
    "    # If image is uint8 numpy array\n",
    "    elif isinstance(image, np.ndarray) and image.dtype == np.uint8:\n",
    "        image = image / 255.0\n",
    "    \n",
    "    # Ensure image is in correct range\n",
    "    plt.imshow(np.clip(image, 0, 1))\n",
    "    \n",
    "    if probabilities is not None:\n",
    "        pred_text = f'Prediction: {classes[prediction]} ({probabilities[prediction]*100:.2f}%)'\n",
    "    else:\n",
    "        pred_text = f'Prediction: {classes[prediction]}'\n",
    "    \n",
    "    if title:\n",
    "        plt.title(f'{title}\\n{pred_text}')\n",
    "    else:\n",
    "        plt.title(pred_text)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop\n",
    "- 1. Random CIFAR-10 image\n",
    "- 2. Custom image\n",
    "- 3. Exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully. Running on cpu\n",
      "\n",
      "Choose an option:\n",
      "1. Test random CIFAR-10 image\n",
      "2. Test custom image\n",
      "3. Exit\n",
      "Files already downloaded and verified\n",
      "\n",
      "Choose an option:\n",
      "1. Test random CIFAR-10 image\n",
      "2. Test custom image\n",
      "3. Exit\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "# Custom or random image prediction\n",
    "def main():\n",
    "    # Model path\n",
    "    model_path = './cifar10_best.pth'\n",
    "    \n",
    "    try:\n",
    "        model, device = load_model(model_path)\n",
    "        print(f\"Model loaded successfully. Running on {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1. Test random CIFAR-10 image\")\n",
    "        print(\"2. Test custom image\")\n",
    "        print(\"3. Exit\")\n",
    "        \n",
    "        choice = input(\"Enter your choice (1-3): \")\n",
    "        \n",
    "        if choice == '1':\n",
    "            image_tensor, true_label, original_image = get_random_cifar_image()\n",
    "            pred, probs = predict_image(model, image_tensor, device)\n",
    "            display_prediction(original_image/255.0, pred, probs, \n",
    "                             f'True Label: {classes[true_label]}')\n",
    "            \n",
    "        elif choice == '2':\n",
    "            image_name = input(\"Enter the image's name: \")\n",
    "            image_path = './manual-batch/' + image_name\n",
    "            try:\n",
    "                print(\"\\nProcessing image...\")\n",
    "                image_tensor, original_image = get_custom_image(image_path)\n",
    "                print(\"Making prediction...\")\n",
    "                pred, probs = predict_image(model, image_tensor, device)\n",
    "                display_prediction(original_image, pred, probs)\n",
    "                \n",
    "                # Print top-3 predictions\n",
    "                top_probs, top_labels = torch.topk(probs, 3)\n",
    "                print(\"\\nTop 3 predictions:\")\n",
    "                for i in range(3):\n",
    "                    print(f\"{classes[top_labels[i]]}: {top_probs[i]*100:.2f}%\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image: {e}\")\n",
    "                \n",
    "        elif choice == '3':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
